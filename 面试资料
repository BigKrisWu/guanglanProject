数据接入：
主要功能是提供探针采集能力，读取资管文件数据，加载groovy脚本主要根据toh提供的资产配置和脚本文件对数据进行解析过滤，转换，去重等步骤，
脚本中会提供临时表与实体表的映射关系和处理规则，以及点边数据的抽取规则（前提需要先创建临时表数据写入sqllite进行数据过滤），将处理后的
数据推送到kafka。端到端(数据接入到数据转换)的数据为了保证某个点或边的数据完整，增加了页号标识，统计出来的数据量按5000一个批次推送，
收到最后一个页号标识代表着某个点或边的数据收全了。数据转换到数据入库没有端到端的保证。

数据转换：
接收来自数据接入功能吐出的数据进行处理，主要是对入图库的数据增加vid（传过来的nativeid即UUID拼接点或边名称算法）生成策略，目的是保证点边之间连接的vid是一致的。
每一个点边都是yaml资产，在yaml中根据target标识 Nebula和DIMPG，如果是nebula则把数据写出到minio文件系统，如果是DIMPG则通过pg数据库消费kafka数据入库

数据入库：
消费minio文件中的数据，默认只要数据写到minio之后，就认为是数据写全了。入库阶段还是按照每次1024条批量写入。

3XL环境信息
nebula9台节点 CPU 670 内存 2600G 总50多台虚拟机
